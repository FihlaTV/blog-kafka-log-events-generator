<?xml version="1.0" encoding="UTF-8"?><!-- 
    For more configuration information and examples see
    http://logback.qos.ch/manual/configuration.html
-->
<configuration debug="true" scan="false">

    <appender name="STASH" class="com.github.danielwegener.logback.kafka.KafkaAppender">

        <encoder class="com.github.danielwegener.logback.kafka.encoding.PatternLayoutKafkaMessageEncoder">
            <!-- encoder is required -->
            <layout class="net.logstash.logback.layout.LoggingEventCompositeJsonLayout">
                <providers>
                    <mdc/>

                    <context/>

                    <version/>

                    <logLevel/>
                    <loggerName/>

                    <pattern>
                        <pattern>
                            {
                            "appName": "testdata",
                            "appVersion": "1.0"
                            }
                        </pattern>
                    </pattern>

                    <threadName/>

                    <message/>

                    <logstashMarkers/>
                    <arguments/>

                    <stackTrace/>
                </providers>
            </layout>
        </encoder>

        <topic>logs</topic>
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.RoundRobinKeyingStrategy" />
        <!--<deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />-->

        <!-- each <producerConfig> translates to regular kafka-client config (format: key=value) -->
        <!-- producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs -->
        <!-- bootstrap.servers is the only mandatory producerConfig -->
        <producerConfig>bootstrap.servers=172.18.0.2:9092</producerConfig>
        <!--<producerConfig>value.serializer=org.apache.kafka.common.serialization.StringSerializer</producerConfig>-->

    </appender>
    <!---->


    <!-- Debugging appender (duplicates the normal log, PLUS any debug messages) -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%date{ISO8601} %c{3} [%mdc{eventId}] - %message%n</pattern>
        </encoder>
    </appender>
    <!---->

    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>./log/events-file.log</file>
        <append>true</append>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>./log/events-file.log.%d{yyyyMMdd}-%i
            </fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>256MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} [%thread] %level{5} %c{3} - %message%n</pattern>
        </encoder>
    </appender>


    <logger name="ro.fortsoft.kafka.testdata" level="INFO" additivity="false">
        <appender-ref ref="FILE"/>
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="STASH"/>
    </logger>

    <logger name="org.apache.kafka" level="INFO" additivity="false">
        <appender-ref ref="CONSOLE"/>
    </logger>

    <!-- ROOT logger setup -->
    <root level="INFO">
        <appender-ref ref="FILE"/>
        <appender-ref ref="CONSOLE"/>
    </root>

</configuration>